---
title: "CLEAR-3 ICA analysis pipeline"
output:
  html_notebook:
    toc: yes
    df_print: paged
    toc_float: yes
    theme: spacelab
  pdf_document:
    toc: yes
---

This is a streamlined version of the analysis done in the manuscript, assembled from a variety of original analysis files. These files still reside in this repository for archival purposes (which means, unfortunately, that we have a certain degree of code duplication). 

The pipeline is divided into three parts: Preprocessing, independent component analysis (ICA), and linear mixed-effects modelling. The meat of the preprocessing code has been delegated to R source files, which can be found in the `src` folder. The ICA and modelling code, on the other hand, is more verbose to allow easier exposition of, e.g., model structure.

```{r setup, warning=FALSE}
knitr::opts_chunk$set(cache = TRUE, message = FALSE)
local <- TRUE

wd <- ""

if (!local) {
  # Cluster environment
  wd <- "~/Documents/Autocorrelation"
  # Base directory for the data set we will create
  dat_dir <- "/project_cephfs/3022017.02/projects/lorkno/data"
} else {
  wd <- "/Volumes/home/preclineu/lorkno/Documents/Autocorrelation"
  # Base directory for the data set we will create
  dat_dir <- "~/HPC_project/data"
}

# For some reason this sets the pwd only for the current scope, which means it 
# does not affect anything outside an if block if you set it there.
# So that's why it's here instead of above.
setwd(wd) 

src_dir <- "src"
source(file.path(src_dir, "load_dependencies.R"))

man_img_dir <- "~/Documents/Writing/Papers/Paper 1/images"
```

# Preprocessing

These functions repair potential file errors, move files into a BIDS-like structure, and then perform filtering and aggregation where necessary.

```{r eval=FALSE}
source(file.path(src_dir, "preproc_all.R"))

dir.create(dat_dir, showWarnings = FALSE, recursive = TRUE)

skip_src_transfer <- TRUE

rearrange_raw_files(skip_src_transfer)

preproc_biaffect()
```

Binds self-report and BiAffect data on the daily level. Also includes a bit of self-report cleaning.

```{r eval=FALSE}
source(file.path(src_dir, "join_selfreport_biaffect.R"))

dat_reg <- join_selfreport_biaffect(
  selfreport_path = file.path(dat_dir, "clear3daily_20221205.sav"),
  inclusion_path = "regression_inclusion_20230314.xlsx"
)
```

Trim preprocessed data to only include baseline data.

```{r eval=FALSE}
source(file.path(src_dir, "trim_baseline.R"))

trim_baseline(
  dat_reg,
  date_path = file.path(dat_dir, "CLEAR3_Biaffect_Leow", "Metadata", 
                        "clear3_start_tx_dates.xlsx"),
  save_path = file.path(dat_dir, "dat_reg_trimmed.rds")
)
```

One can now run `shiny/missingness/app.R` to browse the preprocessed data and select some minimum quality bounds for inclusion in the independent component and modelling analyses.

# ICA

Run the ICA on the semi-contiguous (`dat_reg_semi_contiguous.rds`) and fragmented (`dat_reg_fragmented.rds`) data files created with the Shiny app.

```{r}
source(file.path(src_dir, "ica.R"))
```

## Fragmented ICA

```{r fig.height=10}
ica_frag <- run_icas(file.path(dat_dir, "dat_reg_fragmented_no-tdia.rds"), 
                     ns_comp = c(5, 10, 20),
                     out_path = file.path(dat_dir, "dat_reg_frag_icas.rda"))

fancy_mix_fig(ica_frag[[1]], 
              lims = c(-0.6, 0.6),
              ann_x = -0.75,
              save_path = file.path(man_img_dir, "mixing_matrix_5_frag.pdf"))
fancy_mix_fig(ica_frag[[2]], 
              n_row = 2,
              lims = c(-0.6, 0.6),
              ann_x = -0.78,
              save_path = file.path(man_img_dir, "mixing_matrix_10_frag.pdf"),
              width = 15, height = 15)
fancy_mix_fig(ica_frag[[3]], 
              n_row = 2,
              lims = c(-0.6, 0.6),
              ann_x = -0.9,
              save_path = file.path(man_img_dir, "mixing_matrix_20_frag.pdf"),
              width = 15, height = 15)
```

## Semi-contiguous ICA

```{r fig.height=10}
icas <- run_icas(dat_path = file.path(dat_dir, "dat_reg_semi_contiguous_no-tdia.rds"),
                 ns_comp = c(5, 10, 20),
                 out_path = file.path(dat_dir, "dat_reg_contig_icas.rda"))

fancy_mix_fig(icas$`5`, 
              save_path = file.path(man_img_dir, "mixing_matrix_5.pdf"))
fancy_mix_fig(icas$`10`, n_row = 2, 
              save_path = file.path(man_img_dir, "mixing_matrix_10.pdf"),
              width = 15, height = 15)
fancy_mix_fig(icas$`20`, n_row = 2, lims = c(-0.6, 0.6), 
              save_path = file.path(man_img_dir, "mixing_matrix_20.pdf"),
              width = 15, height = 15)
```

## Within-subject mean-centring

```{r fig.height=10}
ica_norm <- run_icas(dat_path = file.path(dat_dir, "dat_reg_fragmented_no-tdia.rds"),
                     ns_comp = c(5), sub_norm = TRUE)[[1]]

fancy_mix_fig(ica_norm, 
              lims = c(-0.6, 0.6),
              save_path = file.path(man_img_dir, "mixing_matrix_5_norm.pdf"))
```

# Models

This section presents the code and output for running the models. Since validating the model assumptions is a rather space-consuming activity (i.e., lots of plots), it has been delegated to a different file. Take a look at `multilevel_modelling.Rmd` for more information.

```{r}
source(file.path(src_dir, "lmer.R"))
```

## Fragmented

```{r}
ls <- prep_reg_dat(
  dat_path = file.path(dat_dir, "dat_reg_fragmented_no-tdia.rds"),
  ica_path = file.path(dat_dir, "dat_reg_frag_icas.rda")
)

dat_reg_frag <- ls$dat_reg
dat_bi <- ls$dat_bi
dat_sr <- ls$dat_sr
icas <- ls$icas
subs <- ls$subs
dates <- ls$dates
dats_c_frag <- ls$dats_c
```

### Five components

```{r}
dat_c1_frag <- dats_c_frag[[1]]

m5.frag.X1.nlme <- lme(X1 ~ medianIKD +
                         percent95IKD +
                         madIKD +
                         autocorrectRate +
                         backspaceRate +
                         totalKeyPresses +
                         active +
                         upright,
                       random = ~ 1 | subject / week,
                       data = dat_c1_frag)

m5.frag.all.nlme <- dat_c1_frag %>%
  summarize(across(starts_with("X", ignore.case = FALSE), 
                   ~ list(update(m5.frag.X1.nlme, 
                                 reformulate(".", cur_column())))))

estimates_to_csv(file.path(dat_dir, "m5_nlme_p_frag_no-tdia.csv"), 
                           m5.frag.all.nlme, 
                           include_corrected = TRUE)
```

### Ten components

```{r}
dat_c2_frag <- dats_c_frag[[2]]

m10.frag.X1.nlme <- lme(X1 ~ medianIKD +
                           percent95IKD +
                           madIKD +
                           autocorrectRate +
                           backspaceRate +
                           totalKeyPresses +
                           active +
                           upright,
                         random = ~ 1 | subject / week,
                         data = dat_c2_frag)

m10.frag.all.nlme <- dat_c2_frag %>%
  summarize(across(starts_with("X", ignore.case = FALSE), 
                   ~ list(update(m10.frag.X1.nlme, 
                                 reformulate(".", cur_column())))))

estimates_to_csv(file.path(dat_dir, "m10_nlme_p_frag_no-tdia.csv"), 
                 m10.frag.all.nlme, 
                 include_corrected = TRUE,
                 transpose = TRUE)
```

### Twenty components

```{r}
dat_c3_frag <- dats_c_frag[[3]]

m20.frag.X1.nlme <- lme(X1 ~ medianIKD +
                           percent95IKD +
                           madIKD +
                           autocorrectRate +
                           backspaceRate +
                           totalKeyPresses +
                           active +
                           upright,
                         random = ~ 1 | subject / week,
                         data = dat_c3_frag)

m20.frag.all.nlme <- dat_c3_frag %>%
  summarize(across(starts_with("X", ignore.case = FALSE), 
                   ~ list(update(m20.frag.X1.nlme, 
                                 reformulate(".", cur_column())))))

estimates_to_csv(file.path(dat_dir, "m20_nlme_p_frag_no-tdia.csv"), 
                 m20.frag.all.nlme, 
                 include_corrected = TRUE,
                 transpose = TRUE)
```

## Semi-contiguous

```{r}
ls <- prep_reg_dat(
  dat_path = file.path(dat_dir, "dat_reg_semi_contiguous_no-tdia.rds"),
  ica_path = file.path(dat_dir, "dat_reg_contig_icas.rda")
)

dat_reg_contig <- ls$dat_reg
dat_bi <- ls$dat_bi
dat_sr <- ls$dat_sr
icas <- ls$icas
subs <- ls$subs
dates <- ls$dates
dats_c <- ls$dats_c
```

### Five components

```{r}
dat_c1 <- dats_c[[1]]

m5.X1.nlme <- lme(X1 ~ medianIKD +
                   percent95IKD +
                   madIKD +
                   autocorrectRate +
                   backspaceRate +
                   totalKeyPresses +
                   active +
                   upright,
                 random = ~ 1 | subject / week,
                 data = dat_c1)

m5.all.nlme <- dat_c1 %>%
  summarize(across(starts_with("X", ignore.case = FALSE), 
                   ~ list(update(m5.X1.nlme, reformulate(".", cur_column())))))

estimates_to_csv(file.path(dat_dir, "m5_nlme_p_no-tdia.csv"), 
                 m5.all.nlme, 
                 include_corrected = TRUE)
```

### Ten components

```{r}
dat_c2 <- dats_c[[2]]

m10.X1.nlme <- lme(X1 ~ medianIKD +
                     percent95IKD +
                     madIKD +
                     autocorrectRate +
                     backspaceRate +
                     totalKeyPresses +
                     active +
                     upright,
                   random = ~ 1 | subject / week,
                   data = dat_c2)

m10.all.nlme <- dat_c2 %>%
  summarize(across(starts_with("X", ignore.case = FALSE), 
                   ~ list(update(m10.X1.nlme, reformulate(".", cur_column())))))

estimates_to_csv(file.path(dat_dir, "m10_nlme_p_no-tdia.csv"), 
                 m10.all.nlme, 
                 include_corrected = TRUE)
```

### Twenty components

```{r}
dat_c3 <- dats_c[[3]]

m20.X1.nlme <- lme(X1 ~ medianIKD +
                     percent95IKD +
                     madIKD +
                     autocorrectRate +
                     backspaceRate +
                     totalKeyPresses +
                     active +
                     upright,
                   random = ~ 1 | subject / week,
                   data = dat_c3)

m20.all.nlme <- dat_c3 %>%
  summarize(across(starts_with("X", ignore.case = FALSE), 
                   ~ list(update(m20.X1.nlme, reformulate(".", cur_column())))))

estimates_to_csv(file.path(dat_dir, "m20_nlme_p_no-tdia.csv"), 
                 m20.all.nlme, 
                 include_corrected = TRUE)
```

